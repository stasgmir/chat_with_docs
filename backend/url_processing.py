import os
import re
import requests
from bs4 import BeautifulSoup
from pathlib import Path
from langchain_openai import ChatOpenAI


def fetch_url_content(url: str) -> str:


    print(f"\nüåç –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")

    headers = {"User-Agent": "Mozilla/5.0 (ChatWithDocsBot/1.0)"}
    response = requests.get(url, headers=headers, timeout=20)

    if response.status_code != 200:
        raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status_code}")

    content_type = response.headers.get("Content-Type", "").lower()

    if "application/pdf" in content_type or url.endswith(".pdf"):
        print("üìÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω PDF ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Docling...")
        tmp_pdf = Path("temp_url_doc.pdf")
        with open(tmp_pdf, "wb") as f:
            f.write(response.content)
        return f"[PDF —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {tmp_pdf.resolve()}]"

    if "html" in content_type:
        print("üß© –û–±–Ω–∞—Ä—É–∂–µ–Ω HTML ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–≥–æ–≤...")
        soup = BeautifulSoup(response.text, "html.parser")


        for tag in soup(["script", "style", "nav", "footer", "header", "noscript"]):
            tag.decompose()

        text = soup.get_text(separator="\n")
        clean_text = re.sub(r"\n\s*\n+", "\n\n", text).strip()
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(clean_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")
        return clean_text[:50000]


    if "text" in content_type:
        print("üßæ –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ—Å—É—Ä—Å.")
        return response.text[:50000]

    raise Exception("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–∫–∏ –∏–ª–∏ —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞.")



def ask_question_about_url_text(text: str, question: str, openai_api_key: str):

    print(f"\nüí≠ –í–æ–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é: {question}")

    llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=openai_api_key, temperature=0.4)

    prompt = (
        "–í–æ—Ç —Ç–µ–∫—Å—Ç, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã. "
        "–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—Ç–∏ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n\n"
        f"=== –¢–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===\n{text[:15000]}\n\n"
        f"=== –í–æ–ø—Ä–æ—Å ===\n{question}"
    )

    response = llm.invoke(prompt)
    return response.content



def process_url_and_answer(url: str, question: str, openai_api_key: str):


    text = fetch_url_content(url)

    llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=openai_api_key, temperature=0.4)


    summary_prompt = (
        "–°–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–æ–µ (5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n\n"
        f"{text[:10000]}"
    )
    summary = llm.invoke(summary_prompt).content

    answer = ask_question_about_url_text(text, question, openai_api_key)

    return answer, summary



def main():
    print("=" * 60)
    print("üåê URL Content Q&A (Requests + BeautifulSoup + OpenAI)")
    print("=" * 60)

    url = input("üîó –í–≤–µ–¥–∏—Ç–µ —Å—Å—ã–ª–∫—É: ").strip()
    if not url:
        print("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Å—ã–ª–∫–∞.")
        return

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY.")
        return

    try:
        text = fetch_url_content(url)
        print(f"\nüìú –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.")
        print(f"–ü—Ä–µ–≤—å—é:\n{text[:400]}...\n")

        question = input("üí¨ –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É: ").strip()
        if not question:
            print("‚ùå –í–æ–ø—Ä–æ—Å –Ω–µ –∑–∞–¥–∞–Ω.")
            return

        answer = ask_question_about_url_text(text, question, api_key)
        print("\nüß† –û—Ç–≤–µ—Ç:\n" + answer)

    except Exception as e:
        print(f"\n‚úó –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
